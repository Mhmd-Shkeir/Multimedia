{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48164dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #type: ignore\n",
    "from tensorflow.keras.applications import ResNet50 #type: ignore\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout#type: ignore\n",
    "from tensorflow.keras.models import Model #type: ignore\n",
    "from tensorflow.keras.optimizers import Adam #type: ignore\n",
    "from tensorflow.keras.preprocessing import image #type: ignore\n",
    "import splitfolders\n",
    "import os, random, shutil\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2bfeb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)\n",
    "#print(pandas.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849518a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataset_stats.csv')\n",
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, count in zip(df['class'], df['image_count']):\n",
    "    print(name,count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4f101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['avg_width','avg_height']].plot(kind='box')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc119d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src = Path(\"sneakers-dataset\")   # each subfolder = class\n",
    "dst = Path(\"splits\")               # keep OUTSIDE src\n",
    "allowed = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\", \".jfif\"}\n",
    "random.seed(42)\n",
    "\n",
    "# clean/create targets\n",
    "for part in (\"train\",\"val\",\"test\"):\n",
    "    (dst/part).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "total = 0\n",
    "for cls_dir in sorted([d for d in src.iterdir() if d.is_dir()]):\n",
    "    files = [p for p in cls_dir.iterdir() if p.is_file() and p.suffix.lower() in allowed]\n",
    "    if not files:\n",
    "        print(f\"[warn] no images in: {cls_dir}\")\n",
    "        continue\n",
    "\n",
    "    random.shuffle(files)\n",
    "    n = len(files); n_train = int(0.8*n); n_val = int(0.1*n)\n",
    "\n",
    "    splits = {\n",
    "        \"train\": files[:n_train],\n",
    "        \"val\":   files[n_train:n_train+n_val],\n",
    "        \"test\":  files[n_train+n_val:],\n",
    "    }\n",
    "\n",
    "    for part, flist in splits.items():\n",
    "        out = dst/part/cls_dir.name\n",
    "        out.mkdir(parents=True, exist_ok=True)\n",
    "        for f in flist:\n",
    "            shutil.copy2(f, out/f.name)\n",
    "\n",
    "    total += n\n",
    "    print(f\"{cls_dir.name}: {n} -> train {n_train}, val {n_val}, test {n - n_train - n_val}\")\n",
    "\n",
    "print(\"Done. Total images:\", total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,                     # [snippet] scale pixels to [0,1]\n",
    "\n",
    "    rotation_range=20,                  # [snippet] rotate within ±20°\n",
    "    # rotation_range=0                  # disable rotation\n",
    "\n",
    "    width_shift_range=0.10,             # [snippet] horizontal shift up to ±10%\n",
    "    height_shift_range=0.10,            # [snippet] vertical shift up to ±10%\n",
    "    # width_shift_range=0.0             # disable width shift\n",
    "    # height_shift_range=0.0            # disable height shift\n",
    "\n",
    "    shear_range=0.15,                   # [snippet] projective skew\n",
    "    # shear_range=0.0                   # disable shear\n",
    "\n",
    "    zoom_range=0.20,                    # [snippet] zoom in/out up to 20%\n",
    "    # zoom_range=[1.0, 1.2]             # only zoom-in\n",
    "    # zoom_range=[0.8, 1.0]             # only zoom-out\n",
    "\n",
    "    brightness_range=[0.7, 1.3],        # [snippet] random brightness\n",
    "    # brightness_range=None             # disable brightness jitter\n",
    "\n",
    "    channel_shift_range=30,             # [snippet] random RGB shift (color cast)\n",
    "    # channel_shift_range=0             # disable color shift\n",
    "\n",
    "    horizontal_flip=True,               # [snippet] left-right flip\n",
    "    # horizontal_flip=False             # disable flip\n",
    "\n",
    "    fill_mode='nearest'                 # [snippet] fill gaps after transforms\n",
    "    # fill_mode='reflect'               # alternative\n",
    "    # fill_mode='constant'              # with cval=0 (black)\n",
    "    # cval=128                          # used if fill_mode='constant'\n",
    ")\n",
    "\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ae37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_gen.flow_from_directory(\n",
    "    \"./splits/train\", target_size=(224,224),\n",
    "    batch_size=32, shuffle=True, class_mode=\"categorical\", seed=42\n",
    ")\n",
    "val = val_gen.flow_from_directory(\n",
    "    \"./splits/val\", target_size=(224,224),\n",
    "    batch_size=32, shuffle=False, class_mode=\"categorical\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb56a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, numpy as np\n",
    "\n",
    "x, y = next(train)              # one batch\n",
    "for i in range(9):\n",
    "    plt.figure()\n",
    "    plt.imshow(np.clip(x[i], 0, 1))\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a07cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = ResNet50(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# freeze most layers\n",
    "for layer in base.layers[:-10]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = GlobalAveragePooling2D()(base.output)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "out = Dense(train.num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=base.input, outputs=out)\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b0ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "val_loss, val_acc = model.evaluate(val)\n",
    "print(f\"Validation accuracy: {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca5111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "model = tf.keras.models.load_model(\"best_resnet50_sneakers.h5\")\n",
    "\n",
    "# load label mapping\n",
    "with open(\"class_indices.json\") as f:\n",
    "    class_indices = json.load(f)\n",
    "idx_to_class = {v: k for k, v in class_indices.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396a283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./jordan12.jpeg\"\n",
    "img = image.load_img(img_path, target_size=(224,224))   # same size as training\n",
    "x = image.img_to_array(img)\n",
    "x = x / 255.0   \n",
    "\n",
    "plt.imshow(x)\n",
    "plt.axis(\"off\")\n",
    "plt.show()                                        # same rescale\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "pred = model.predict(x)\n",
    "i = np.argmax(pred[0])\n",
    "print(\"Predicted class:\", idx_to_class[i])\n",
    "print(\"Confidence:\", pred[0][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bfc08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# community model with 'shoe' class (example, replace if removed)\n",
    "model_det = YOLO(\"yolov8s.pt\")\n",
    "results = model_det(\"./samba.jpg\", save=True, save_crop=True, project=\"./\", name=\"footwear_crops\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d11eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sneaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
